{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85366389",
   "metadata": {},
   "source": [
    "# Binary Classification: Cats vs Dogs (Transfer Learning)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df650e6",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d76321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os, datetime, random, shutil, zipfile, warnings\n",
    "import numpy as np, matplotlib.pyplot as plt, tensorflow as tf, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# ðŸ”¹ Suppress ALL warnings globally\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ðŸ”¹ Mixed Precision\n",
    "tf.keras.mixed_precision.set_global_policy('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694feb72",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "data_file_name = \"catsdogs.zip\"\n",
    "urllib.request.urlretrieve(data_url, data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c263d61",
   "metadata": {},
   "source": [
    "### Downloading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weights_file = \"inception_v3.h5\"\n",
    "urllib.request.urlretrieve(weights_url, weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821a738",
   "metadata": {},
   "source": [
    "### Unzipping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2440bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./catsdogs.zip\")\n",
    "os.remove(\"./CDLA-Permissive-2.0.pdf\")\n",
    "os.remove(\"./readme[1].txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafcf605",
   "metadata": {},
   "source": [
    "### Moving files for train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a566db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_percentage(src_dir, dest_dir, percentage):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    all_files = os.listdir(src_dir)\n",
    "    num_files_to_move = int(len(all_files) * percentage/100)\n",
    "    random.shuffle(all_files)\n",
    "\n",
    "    for filename in tqdm(all_files[:num_files_to_move], desc=f\"Moving {percentage}% of images\"):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            src_path = os.path.join(src_dir, filename)\n",
    "            dest_path = os.path.join(dest_dir, filename)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "\n",
    "dog_src_dir = \"./PetImages/Dog\"\n",
    "dog_dest_dir = \"./PetImages/test/dog\"\n",
    "move_percentage(dog_src_dir, dog_dest_dir, 20)\n",
    "\n",
    "cat_src_dir = \"./PetImages/Cat\"\n",
    "cat_dest_dir = \"./PetImages/test/cat\"\n",
    "move_percentage(cat_src_dir, cat_dest_dir, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1335833",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"./PetImages/Cat\"\n",
    "dest_path = \"./PetImages/train\"\n",
    "os.makedirs(dest_path, exist_ok=True)\n",
    "shutil.move(src_path, dest_path)\n",
    "\n",
    "src_path = \"./PetImages/Dog\"\n",
    "dest_path = \"./PetImages/train\"\n",
    "os.makedirs(dest_path, exist_ok=True)\n",
    "shutil.move(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(\"./PetImages/train/Dog\", \"./PetImages/train/dog\")\n",
    "os.rename(\"./PetImages/train/Cat\", \"./PetImages/train/cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b0569",
   "metadata": {},
   "source": [
    "### Remove corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupted_images(directory):\n",
    "    removed_files = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Open the image to check if it's valid\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # Verify file integrity\n",
    "            except (IOError, SyntaxError):\n",
    "                print(f\"Corrupted file removed: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "                removed_files += 1\n",
    "    print(f\"\\nâœ… Total corrupted files removed: {removed_files}\")\n",
    "\n",
    "# Clean both train and test datasets\n",
    "remove_corrupted_images(\"./PetImages/train\")\n",
    "remove_corrupted_images(\"./PetImages/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0164199",
   "metadata": {},
   "source": [
    "### Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1587e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"./PetImages/train\"\n",
    "TEST_DIR = \"./PetImages/test\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "                                    brightness_range=[0.8, 1.2],\n",
    "                                    fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(TRAINING_DIR, target_size=(150, 150), batch_size=128, class_mode='binary', \n",
    "                                                  color_mode='rgb', shuffle=True)\n",
    "test_dataset = test_datagen.flow_from_directory(TEST_DIR, target_size=(150, 150), batch_size=128, class_mode='binary', \n",
    "                                                color_mode='rgb', shuffle=False)\n",
    "print(train_dataset.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_dataset)\n",
    "\n",
    "num_images = 16\n",
    "cols=8; rows=num_images//cols\n",
    "\n",
    "figure, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3), dpi=300)\n",
    "for i in range(num_images):\n",
    "    ax = axes[i//cols, i%cols]\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(f\"Label: {labels[i]:0.0f}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Training Images\", fontsize=16)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way to get one batch from a DirectoryIterator\n",
    "images, labels = next(test_dataset)\n",
    "\n",
    "num_images = 16\n",
    "cols=8; rows=num_images//cols\n",
    "\n",
    "figure, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3), dpi=300)\n",
    "for i in range(num_images):\n",
    "    ax = axes[i//cols, i%cols]\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(f\"Label: {labels[i]:0.0f}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Testing Images\", fontsize=16)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027d07a",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434dbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = tf.keras.applications.InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)\n",
    "pre_trained_model.load_weights(\"./inception_v3.h5\")\n",
    "pre_trained_model.trainable = False\n",
    "#pre_trained_model.summary()\n",
    "output = pre_trained_model.output\n",
    "\n",
    "x = tf.keras.layers.Flatten()(output)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=pre_trained_model.input, outputs=x, name=\"Classifier\")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2397be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=1e-4, first_decay_steps=157, alpha=0.1)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=scheduler), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d433f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec58616",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='best_model.weights.h5', \n",
    "                                                save_best_only=True, save_weights_only=True, \n",
    "                                                monitor='val_loss', mode='min', verbose=1),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)]\n",
    "\n",
    "history = model.fit(train_dataset, epochs=100, validation_data=test_dataset, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea346e",
   "metadata": {},
   "source": [
    "### Plotting Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118596b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "figure = plt.figure(figsize=(12, 4), dpi=300)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label=\"Training Accuracy\"); plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy'); plt.xlabel('Epochs'); plt.ylabel('Accuracy')\n",
    "plt.legend(); plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label=\"Training Loss\"); plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "plt.title('Training and validation loss'); plt.xlabel('Epochs'); plt.ylabel('Loss')\n",
    "plt.legend(); plt.grid()\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3b813",
   "metadata": {},
   "source": [
    "## Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d5487",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset, verbose=1)\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y_true = test_dataset.labels\n",
    "class_labels = list(test_dataset.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
    "\n",
    "print(\"ðŸ“Š Classification Report\")\n",
    "print(\"=======================\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cc087",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5), dpi=100)\n",
    "sns.heatmap(cm, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=8)\n",
    "plt.ylabel('True Label', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a4bef",
   "metadata": {},
   "source": [
    "### ROC curve & AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# 1. Calculate the values for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, predictions)\n",
    "\n",
    "# 2. Calculate the AUC score\n",
    "auc = roc_auc_score(y_true, predictions)\n",
    "\n",
    "# 3. Plot the curve\n",
    "plt.figure(figsize=(7, 6), dpi=100)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})')\n",
    "#plt.plot([0, 1], [0, 1], 'r--', label='Random Guess') # Dashed line for random chance\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23864b51",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf43a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "path = \"./test_imgs/cat3.jpg\"\n",
    "img = load_img(path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "classification = model.predict(img_array)\n",
    "if classification[0][0]>0.5:\n",
    "    cls = \"Dog\"\n",
    "    confidence = classification[0][0]\n",
    "else:\n",
    "    cls = \"Cat\"\n",
    "    confidence = 1 - classification[0][0]\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=100)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Class: {cls}\\nConfidence: {confidence:.4f}\", fontsize=8)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glob Venv (TF-ML)",
   "language": "python",
   "name": "glob_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
